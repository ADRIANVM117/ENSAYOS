{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dominio de sentencias assert\n",
    "### Adrián Vázquez\n",
    "#### 05/07/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Escriba un mensaje de fallo de prueba informativo. </b>\n",
    "\n",
    "- Los informes de resultados de las pruebas son mucho más fáciles de leer cuando se hace un buen uso del argumento opcional del mensaje de la sentencia assert.\n",
    "\n",
    "- En un ejercicio anterior, escribiste una prueba para la función convert_to_int(). La función toma como argumento una cadena de valores enteros con comas como separadores de miles, por ejemplo \"2,081\", y debería devolver el número entero 2081.\n",
    "\n",
    "- En este ejercicio, reescribirás la prueba llamada test_on_string_with_one_comma() para que imprima un mensaje informativo si la prueba falla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessing_helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9c7a3f949de4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocessing_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_to_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_on_string_with_one_comma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_argument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2,081\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2081\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'preprocessing_helpers'"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "from preprocessing_helpers import convert_to_int\n",
    "def test_on_string_with_one_comma():\n",
    "    test_argument = \"2,081\"\n",
    "    expected = 2081\n",
    "    actual = convert_to_int(test_argument)\n",
    "    # Format the string with the actual return value\n",
    "    message = \"convert_to_int('2,081') should return the int 2081, but it actually returned {0}\".format(actual)\n",
    "    # Write the assert statement which prints message on failure\n",
    "    assert actual is expected, message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> Ejemplo de la salida de `!pytest test_convert_to_int.py` </b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "!pytest test_convert_to_int.py\n",
    "============================================================================================================================================================================================= test session starts ==============================================================================================================================================================================================\n",
    "platform linux -- Python 3.6.7, pytest-5.2.2, py-1.9.0, pluggy-0.13.1\n",
    "Matplotlib: 3.1.1\n",
    "Freetype: 2.6.1\n",
    "rootdir: /tmp/tmpn4semj6l\n",
    "plugins: mock-1.11.2, mpl-0.10\n",
    "collecting ...\n",
    "collected 1 item\n",
    "test_convert_to_int.py F                                                                                                                                                                                                                                                                                                                                                                                 [100%]\n",
    "=================================================================================================================================================================================================== FAILURES ===================================================================================================================================================================================================\n",
    "________________________________________________________________________________________________________________________________________________________________________________________ test_on_string_with_one_comma _________________________________________________________________________________________________________________________________________________________________________________________\n",
    "    def test_on_string_with_one_comma():\n",
    "        test_argument = \"2,081\"\n",
    "        expected = 2081\n",
    "        actual = convert_to_int(test_argument)\n",
    "        message = \"convert_to_int('2,081') should return the int 2081, but it actually returned {0}\".format(actual)\n",
    ">       assert actual == expected, message\n",
    "E       AssertionError: convert_to_int('2,081') should return the int 2081, but it actually returned None\n",
    "E       assert None == 2081\n",
    "test_convert_to_int.py:10: AssertionError\n",
    "=========================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> CONCLUSION </B>\n",
    "\n",
    "- La prueba falla porque  convert_to_int(\"2,081\") regresa  None and y no el entero 2081."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Probando los valores de retorno de los flotadores. </b>\n",
    "\n",
    "- La función get_data_as_numpy_array() (que se llamaba mystery_function() en uno de los ejercicios anteriores) toma dos argumentos: la ruta a un fichero de datos limpio y el número de columnas de datos en el fichero . Se ha impreso un archivo de ejemplo en la consola de IPython. Contiene tres filas.\n",
    "\n",
    "- La función convierte los datos en una matriz NumPy 3x2 con dtype=float64. El valor de retorno esperado se ha almacenado en una variable llamada expected. Imprímelo para verlo.\n",
    "\n",
    "- Las zonas de las viviendas están en la primera columna y los precios de las viviendas en la segunda. Esta matriz será las características que se alimentarán al modelo de regresión lineal para el aprendizaje.\n",
    "\n",
    "- El valor de retorno contiene flotadores. Por lo tanto, hay que tener especial cuidado al escribir pruebas unitarias para esta función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'as_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9fcd5d39323c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mas_numpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_data_as_numpy_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_on_clean_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     expected = np.array([[2081.0, 314942.0],\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'as_numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "from as_numpy import get_data_as_numpy_array\n",
    "def test_on_clean_file():\n",
    "    expected = np.array([[2081.0, 314942.0],\n",
    "                       [1059.0, 186606.0],\n",
    "               [1148.0, 206186.0]\n",
    "                       ]\n",
    "                       )\n",
    "    actual = get_data_as_numpy_array(\"example_clean_data.txt\", num_columns=2)\n",
    "    message = \"Expected return value: {0}, Actual return value: {1}\".format(expected, actual)\n",
    "  # Complete the assert statement\n",
    "    assert actual == pytest.approx(expected), message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> with  </b> \n",
    "\n",
    "- Cualquier codigo que este dentro de la declaración with se conoce como contexto \n",
    "\n",
    "- La instrucción with toma un solo argumento, que se conoce como administrador de contexto "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Practicar el gestor de contexto </b>\n",
    "\n",
    "- En pytest, puede comprobar si una función lanza una excepción utilizando un gestor de contexto. Practiquemos la comprensión de este importante gestor de contexto, la sentencia with y la cláusula as.\n",
    "\n",
    "- En cualquier paso, no dudes en ejecutar el código pulsando el botón \"Ejecutar código\" y comprueba si la salida coincide con tus expectativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completa la sentencia with con un gestor de contexto que silencie el ValueError levantado en el contexto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "# Fill in with a context manager that will silence the ValueError\n",
    "with pytest.raises(ValueError):\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Completar la sentencia with con un gestor de contexto que lance Failed si no se lanza ningún OSError en el contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytest raised an exception because no OSError was raised in the context.\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "try:\n",
    "    # Fill in with a context manager that raises Failed if no OSError is raised\n",
    "    with pytest.raises(OSError):\n",
    "        raise ValueError\n",
    "except:\n",
    "    print(\"pytest raised an exception because no OSError was raised in the context.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extienda la sentencia with para que cualquier ValueError levantado sea almacenado en la variable exc_info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "# Store the raised ValueError in the variable exc_info\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    raise ValueError(\"Silence me!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escriba una sentencia assert para comprobar si el ValueError levantado contiene el mensaje \"¡Silencio!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    raise ValueError(\"Silence me!\")\n",
    "# Check if the raised ValueError contains the correct message\n",
    "assert exc_info.match('Silence me!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Prueba unitaria de ValueError. </b>\n",
    "\n",
    "- A veces, quieres que una función lance una excepción cuando se llama con argumentos erróneos. Esto evita que la función devuelva resultados sin sentido o excepciones difíciles de interpretar. Este es un comportamiento importante que debe ser probado por la unidad.\n",
    "\n",
    "- ¿Recuerdas la función split_into_training_and_testing_sets()? Toma como argumento un array de NumPy que contiene el área de la vivienda y los precios. La función divide aleatoriamente la matriz por filas en matrices de entrenamiento y de prueba en la proporción 3:1, y devuelve las matrices resultantes en una tupla.\n",
    "\n",
    "- Si la matriz del argumento sólo tiene una fila, la matriz de prueba estará vacía. Para evitar esta situación, se quiere que la función no devuelva nada, sino que lance un ValueError con el mensaje \"Argument data_array debe tener al menos 2 filas, en realidad sólo tiene 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-17750ce704ec>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-17750ce704ec>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    split_into_training_and_testing_sets(test_argument)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "from train import split_into_training_and_testing_sets\n",
    "def test_on_one_row():\n",
    "    test_argument = np.array([[1382.0, 390167.0]])\n",
    "    # Store information about raised ValueError in exc_info\n",
    "    with pytest.raises(ValueError) as exc_info:\n",
    "    split_into_training_and_testing_sets(test_argument)\n",
    "    expected_error_msg = \"Argument data_array must have at least 2 rows, it actually has just 1\"\n",
    "    # Check if the raised ValueError contains the correct message\n",
    "    assert exc_info.match(expected_error_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -K Option "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
